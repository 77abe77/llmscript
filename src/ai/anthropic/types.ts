/**
 * Anthropic: Models for text generation
 * @export
 */
export enum AnthropicModel {
  Claude3Opus = 'claude-3-opus-20240229',
  Claude3Sonnet = 'claude-3-sonnet-20240229',
  Claude3Haiku = 'claude-3-haiku-20240307',
  Claude21 = 'claude-2.1',
  ClaudeInstant12 = 'claude-instant-1.2'
}

/**
 * Anthropic: Model options for text generation
 * @export
 */
export type AnthropicConfig = {
  model: AnthropicModel;
  maxTokens: number;
  temperature: number;
  topP: number;
  topK?: number;
  stream?: boolean;
  stopSequences?: string[];
};

export type AnthropicCompletionRequest = {
  stop_sequences: readonly string[];
  metadata?: {
    user_id?: string;
  };
  model: AnthropicModel | string;
  prompt: string;
  max_tokens_to_sample: number;
  temperature: number;
  top_p?: number;
  top_k?: number;
  stream?: boolean;
};

export type AnthropicCompletionResponse = {
  completion: string;
  stop_reason?: string | null;
  model: string;
};

// Type for the request to create a message using Anthropic's Messages API
export type AnthropicChatRequest = {
  model: string; // Identifier for the model to use
  messages: {
    role: 'user' | 'assistant'; // Role of the message sender
    content:
      | string
      | {
          // Content of the message
          type: 'text' | 'image'; // Type of content
          text?: string; // Text content (if type is 'text')
          source?: {
            // Image content (if type is 'image')
            type: 'base64'; // Encoding type for the image
            media_type: 'image/jpeg' | 'image/png' | 'image/gif' | 'image/webp'; // MIME type of the image
            data: string; // Base64-encoded image data
          };
        }[];
  }[];
  system?: string; // Optional system prompt for providing context or instructions
  max_tokens: number; // Maximum number of tokens to generate
  // Optional metadata about the request
  stop_sequences?: string[]; // Custom sequences that trigger the end of generation
  stream?: boolean; // Whether to stream the response incrementally
  temperature?: number; // Randomness of the response
  top_p?: number; // Nucleus sampling probability
  top_k?: number; // Sample from the top K options
  metadata?: {
    user_id: string;
  };
};

export type AnthropicChatResponse = {
  id: string; // Unique identifier for the response
  type: 'message'; // Object type, always 'message' for this API
  role: 'assistant'; // Conversational role of the generated message, always 'assistant'
  content: {
    // Content generated by the model
    type: 'text'; // Currently, the only type in responses is "text"
    text: string; // Text content generated by the model
  }[];
  model: string; // The model that handled the request
  stop_reason: 'end_turn' | 'max_tokens' | 'stop_sequence'; // Reason the generation ended
  stop_sequence?: string; // Which custom stop sequence was generated, if any
  usage: {
    // Billing and rate-limit usage information
    input_tokens: number; // The number of input tokens which were used
    output_tokens: number; // The number of output tokens generated
  };
};

export type AnthropicChatError = {
  type: 'error';
  error: {
    type: 'authentication_error';
    message: string;
  };
};

// Base interface for all event types in the stream
interface AnthropicStreamEvent {
  type: string;
}

// Represents the start of a message with an empty content array
export interface MessageStartEvent extends AnthropicStreamEvent {
  message: {
    id: string;
    type: 'message';
    role: 'assistant';
    content: [];
    model: string;
    stop_reason: null | string;
    stop_sequence: null | string;
    usage: {
      input_tokens: number;
      output_tokens: number;
    };
  };
}

// Indicates the start of a content block within a message
export interface ContentBlockStartEvent extends AnthropicStreamEvent {
  index: number;
  content_block: {
    type: 'text';
    text: string;
  };
}

// Represents incremental updates to a content block
export interface ContentBlockDeltaEvent extends AnthropicStreamEvent {
  index: number;
  delta: {
    type: 'text_delta';
    text: string;
  };
}

// Marks the end of a content block within a message
interface ContentBlockStopEvent extends AnthropicStreamEvent {
  index: number;
}

// Indicates top-level changes to the final message object
export interface MessageDeltaEvent extends AnthropicStreamEvent {
  delta: {
    stop_reason: 'end_turn' | 'max_tokens' | 'stop_sequence' | null;
    stop_sequence: string | null;
    usage: {
      output_tokens: number;
    };
  };
}

// Marks the end of a message
type MessageStopEvent = AnthropicStreamEvent;

// Represents a ping event, which can occur any number of times
type PingEvent = AnthropicStreamEvent;

// Represents an error event
interface ErrorEvent extends AnthropicStreamEvent {
  error: {
    type: 'overloaded_error' | string;
    message: string;
  };
}

// Union type for all possible event types in the stream
type AnthropicStreamEventType =
  | MessageStartEvent
  | ContentBlockStartEvent
  | ContentBlockDeltaEvent
  | ContentBlockStopEvent
  | MessageDeltaEvent
  | MessageStopEvent
  | PingEvent
  | ErrorEvent;

// Type for the response delta in streaming mode, using generic to allow flexibility
export interface AnthropicResponseDelta<T> {
  id: string;
  object: 'message';
  model: string;
  events: T[]; // Array of all event types that can occur in the stream
  usage?: {
    input_tokens: number;
    output_tokens: number;
  };
}

// Specific type for handling text deltas in the streaming response
export type AnthropicChatResponseDelta =
  AnthropicResponseDelta<AnthropicStreamEventType>;
