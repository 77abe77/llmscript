<!DOCTYPE html><html class="default" lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="IE=edge"/><title>@ax-llm/ax</title><meta name="description" content="Documentation for @ax-llm/ax"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="assets/style.css"/><link rel="stylesheet" href="assets/highlight.css"/><script defer src="assets/main.js"></script><script async src="assets/icons.js" id="tsd-icons-script"></script><script async src="assets/search.js" id="tsd-search-script"></script><script async src="assets/navigation.js" id="tsd-nav-script"></script></head><body><script>document.documentElement.dataset.theme = localStorage.getItem("tsd-theme") || "os";document.body.style.display="none";setTimeout(() => app?app.showPage():document.body.style.removeProperty("display"),500)</script><header class="tsd-page-toolbar"><div class="tsd-toolbar-contents container"><div class="table-cell" id="tsd-search" data-base="."><div class="field"><label for="tsd-search-field" class="tsd-widget tsd-toolbar-icon search no-caption"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><use href="assets/icons.svg#icon-search"></use></svg></label><input type="text" id="tsd-search-field" aria-label="Search"/></div><div class="field"><div id="tsd-toolbar-links"></div></div><ul class="results"><li class="state loading">Preparing search index...</li><li class="state failure">The search index is not available</li></ul><a href="index.html" class="title">@ax-llm/ax</a></div><div class="table-cell" id="tsd-widgets"><a href="#" class="tsd-widget tsd-toolbar-icon menu no-caption" data-toggle="menu" aria-label="Menu"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><use href="assets/icons.svg#icon-menu"></use></svg></a></div></div></header><div class="container container-main"><div class="col-content"><div class="tsd-page-title"><h2>@ax-llm/ax</h2></div><div class="tsd-panel tsd-typography"><a id="md:ax---build-llms-powered-agents-typescript" class="tsd-anchor"></a><h1><a href="#md:ax---build-llms-powered-agents-typescript">Ax - Build LLMs Powered Agents (Typescript)</a></h1><p>JS/TS library to make to easy to build with agents and agentic workflows with LLMs. Full support for various LLMs and VectorDBs, Function Calling, Chain-of-Thought, RAG, Semantic Router and more. Based on the popular Stanford DSP paper. Build agents or teams of agents to solve complex problems.</p>
<p><a href="https://www.npmjs.com/package/@ax-llm/ax"><img src="https://img.shields.io/npm/v/ax?style=for-the-badge&color=green" alt="NPM Package"></a>
<a href="https://twitter.com/dosco"><img src="https://img.shields.io/twitter/follow/dosco?style=for-the-badge&color=red" alt="Twitter"></a>
<a href="https://discord.gg/DSHg3dU7dW"><img src="https://dcbadge.vercel.app/api/server/DSHg3dU7dW?style=for-the-badge" alt="Discord Chat"></a></p>
<p><img src="https://github.com/dosco/llm-client/assets/832235/b959fdd6-c723-49b1-9fb9-bf879e75c147" alt="llama-small"></p>
<a id="md:build-with-prompt-signatures" class="tsd-anchor"></a><h2><a href="#md:build-with-prompt-signatures">Build with prompt signatures</a></h2><p>Ax is an easy to use library built around &quot;Prompt Signatures&quot; from the <code>Stanford DSP</code> paper. This library will automatically generate efficient and typed prompts from prompt signatures like <code>question:string -&gt; answer:string</code>.</p>
<p>Build powerful workflows using components like RAG, ReAcT, Chain of Thought, Function calling, Agents, etc all built on prompt signatures and easy to compose together to build whatever you want. Using prompt signatures automatically gives you the ability to fine tune your prompt programs using optimizers. Tune with a larger model and have your program run efficiently on a smaller model. The tuning here is not the traditional model tuning but what we call prompt tuning.</p>
<a id="md:why-use-ax" class="tsd-anchor"></a><h2><a href="#md:why-use-ax">Why use Ax?</a></h2><ul>
<li>Support for various LLMs and Vector DBs</li>
<li>Prompts auto-generated from simple signatures</li>
<li>Multi-Hop RAG, ReAcT, CoT, Function Calling and more</li>
<li>Build Agents that can call other agents</li>
<li>Convert docs of any format to text</li>
<li>RAG, smart chunking, embedding, querying</li>
<li>Output field processing, validation while streaming</li>
<li>Automatic prompt tuning using optimizers</li>
<li>OpenTelemetry tracing / observability</li>
<li>Production ready Typescript code</li>
<li>Lite weight, zero-dependencies</li>
</ul>
<a id="md:whats-a-prompt-signature" class="tsd-anchor"></a><h2><a href="#md:whats-a-prompt-signature">Whats a prompt signature?</a></h2><img width="860" alt="shapes at 24-03-31 00 05 55" src="https://github.com/dosco/llm-client/assets/832235/0f0306ea-1812-4a0a-9ed5-76cd908cd26b">

<p>Efficient type-safe prompts are auto-generated from a simple signature. A prompt signature is made of a <code>&quot;task description&quot; inputField:type &quot;field description&quot; -&gt; outputField:type&quot;</code>. The idea behind prompt signatures is based off work done in the &quot;Demonstrate-Search-Predict&quot; paper.</p>
<p>You can have multiple input and output fields and each field has one of these types <code>string</code>, <code>number</code>, <code>boolean</code>, <code>json</code> or a array of any of these eg. <code>string[]</code>. When a type is not defined it defaults to <code>string</code>. When the <code>json</code> type if used the underlying AI is encouraged to generate correct JSON.</p>
<a id="md:llms-supported" class="tsd-anchor"></a><h2><a href="#md:llms-supported">LLMs Supported</a></h2><table>
<thead>
<tr>
<th>Provider</th>
<th>Best Models</th>
<th>Tested</th>
</tr>
</thead>
<tbody><tr>
<td>OpenAI</td>
<td>GPT: 4o, 4T, 4, 3.5</td>
<td>ðŸŸ¢ 100%</td>
</tr>
<tr>
<td>Azure OpenAI</td>
<td>GPT: 4, 4T, 3.5</td>
<td>ðŸŸ¢ 100%</td>
</tr>
<tr>
<td>Together</td>
<td>Several OSS Models</td>
<td>ðŸŸ¢ 100%</td>
</tr>
<tr>
<td>Cohere</td>
<td>CommandR, Command</td>
<td>ðŸŸ¢ 100%</td>
</tr>
<tr>
<td>Anthropic</td>
<td>Claude 2, Claude 3</td>
<td>ðŸŸ¢ 100%</td>
</tr>
<tr>
<td>Mistral</td>
<td>7B, 8x7B, S, M &amp; L</td>
<td>ðŸŸ¢ 100%</td>
</tr>
<tr>
<td>Groq</td>
<td>Lama2-70B, Mixtral-8x7b</td>
<td>ðŸŸ¢ 100%</td>
</tr>
<tr>
<td>DeepSeek</td>
<td>Chat and Code</td>
<td>ðŸŸ¢ 100%</td>
</tr>
<tr>
<td>Ollama</td>
<td>All models</td>
<td>ðŸŸ¢ 100%</td>
</tr>
<tr>
<td>Google Gemini</td>
<td>Gemini: Flash, Pro</td>
<td>ðŸŸ¢ 100%</td>
</tr>
<tr>
<td>Hugging Face</td>
<td>OSS Model</td>
<td>ðŸŸ¡ 50%</td>
</tr>
</tbody></table>
<a id="md:install" class="tsd-anchor"></a><h2><a href="#md:install">Install</a></h2><pre><code class="language-bash"><span class="hl-0">npm</span><span class="hl-1"> </span><span class="hl-2">install</span><span class="hl-1"> </span><span class="hl-2">@ax-llm/ax</span><br/><span class="hl-3"># or</span><br/><span class="hl-0">yarn</span><span class="hl-1"> </span><span class="hl-2">add</span><span class="hl-1"> </span><span class="hl-2">@ax-llm/ax</span>
</code><button>Copy</button></pre>
<a id="md:example-using-chain-of-thought-to-summarize-text" class="tsd-anchor"></a><h2><a href="#md:example-using-chain-of-thought-to-summarize-text">Example: Using chain-of-thought to summarize text</a></h2><pre><code class="language-typescript"><span class="hl-4">import</span><span class="hl-1"> { </span><span class="hl-5">AI</span><span class="hl-1">, </span><span class="hl-5">ChainOfThought</span><span class="hl-1">, </span><span class="hl-5">OpenAIArgs</span><span class="hl-1"> } </span><span class="hl-4">from</span><span class="hl-1"> </span><span class="hl-2">&#39;@ax-llm/ax&#39;</span><span class="hl-1">;</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">textToSummarize</span><span class="hl-1"> = </span><span class="hl-2">`</span><br/><span class="hl-2">The technological singularityâ€”or simply the singularity[1]â€”is a hypothetical future point in time at which technological growth becomes uncontrollable and irreversible, resulting in unforeseeable changes to human civilization.[2][3] ...`</span><span class="hl-1">;</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">ai</span><span class="hl-1"> = </span><span class="hl-0">AI</span><span class="hl-1">(</span><span class="hl-2">&#39;openai&#39;</span><span class="hl-1">, { </span><span class="hl-5">apiKey:</span><span class="hl-1"> </span><span class="hl-5">process</span><span class="hl-1">.</span><span class="hl-5">env</span><span class="hl-1">.</span><span class="hl-7">OPENAI_APIKEY</span><span class="hl-1"> } </span><span class="hl-4">as</span><span class="hl-1"> </span><span class="hl-8">OpenAIArgs</span><span class="hl-1">);</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">gen</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">ChainOfThought</span><span class="hl-1">(</span><br/><span class="hl-1">  </span><span class="hl-5">ai</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-2">`textToSummarize -&gt; shortSummary &quot;summarize in 5 to 10 words&quot;`</span><br/><span class="hl-1">);</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">res</span><span class="hl-1"> = </span><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-5">gen</span><span class="hl-1">.</span><span class="hl-0">forward</span><span class="hl-1">({ </span><span class="hl-5">textToSummarize</span><span class="hl-1"> });</span><br/><br/><span class="hl-5">console</span><span class="hl-1">.</span><span class="hl-0">log</span><span class="hl-1">(</span><span class="hl-2">&#39;&gt;&#39;</span><span class="hl-1">, </span><span class="hl-5">res</span><span class="hl-1">);</span>
</code><button>Copy</button></pre>
<a id="md:example-building-an-agent" class="tsd-anchor"></a><h2><a href="#md:example-building-an-agent">Example: Building an agent</a></h2><p>Use the agent prompt (framework) to build agents that work with other agents to complete tasks. Agents are easy to build with prompt signatures. Try out the agent example.</p>
<pre><code class="language-typescript"><span class="hl-1"># </span><span class="hl-5">npm</span><span class="hl-1"> </span><span class="hl-5">run</span><span class="hl-1"> </span><span class="hl-5">tsx</span><span class="hl-1"> ./</span><span class="hl-5">src</span><span class="hl-1">/</span><span class="hl-5">examples</span><span class="hl-1">/</span><span class="hl-5">agent</span><span class="hl-1">.</span><span class="hl-5">ts</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">researcher</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">Agent</span><span class="hl-1">(</span><span class="hl-5">ai</span><span class="hl-1">, {</span><br/><span class="hl-1">  </span><span class="hl-5">name:</span><span class="hl-1"> </span><span class="hl-2">&#39;researcher&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">description:</span><span class="hl-1"> </span><span class="hl-2">&#39;Researcher agent&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">signature:</span><span class="hl-1"> </span><span class="hl-2">`physicsQuestion &quot;physics questions&quot; -&gt; answer &quot;reply in bullet points&quot;`</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">summarizer</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">Agent</span><span class="hl-1">(</span><span class="hl-5">ai</span><span class="hl-1">, {</span><br/><span class="hl-1">  </span><span class="hl-5">name:</span><span class="hl-1"> </span><span class="hl-2">&#39;summarizer&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">description:</span><span class="hl-1"> </span><span class="hl-2">&#39;Summarizer agent&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">signature:</span><span class="hl-1"> </span><span class="hl-2">`text &quot;text so summarize&quot; -&gt; shortSummary &quot;summarize in 5 to 10 words&quot;`</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">agent</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">Agent</span><span class="hl-1">(</span><span class="hl-5">ai</span><span class="hl-1">, {</span><br/><span class="hl-1">  </span><span class="hl-5">name:</span><span class="hl-1"> </span><span class="hl-2">&#39;agent&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">description:</span><span class="hl-1"> </span><span class="hl-2">&#39;A an agent to research complex topics&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">signature:</span><span class="hl-1"> </span><span class="hl-2">`question -&gt; answer`</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">agents:</span><span class="hl-1"> [</span><span class="hl-5">researcher</span><span class="hl-1">, </span><span class="hl-5">summarizer</span><span class="hl-1">]</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-5">agent</span><span class="hl-1">.</span><span class="hl-0">forward</span><span class="hl-1">({ </span><span class="hl-5">questions:</span><span class="hl-1"> </span><span class="hl-2">&quot;How many atoms are there in the universe&quot;</span><span class="hl-1"> })</span>
</code><button>Copy</button></pre>
<a id="md:fast-llm-router" class="tsd-anchor"></a><h2><a href="#md:fast-llm-router">Fast LLM Router</a></h2><p>A special router that uses no LLM calls only embeddings to route user requests smartly.</p>
<p>Use the Router to efficiently route user queries to specific routes designed to handle certain types of questions or tasks. Each route is tailored to a particular domain or service area. Instead of using a slow or expensive LLM to decide how input from the user should be handled use our fast &quot;Semantic Router&quot; that uses inexpensive and fast embedding queries.</p>
<pre><code class="language-typescript"><span class="hl-1"># </span><span class="hl-5">npm</span><span class="hl-1"> </span><span class="hl-5">run</span><span class="hl-1"> </span><span class="hl-5">tsx</span><span class="hl-1"> ./</span><span class="hl-5">src</span><span class="hl-1">/</span><span class="hl-5">examples</span><span class="hl-1">/</span><span class="hl-5">routing</span><span class="hl-1">.</span><span class="hl-5">ts</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">customerSupport</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">Route</span><span class="hl-1">(</span><span class="hl-2">&#39;customerSupport&#39;</span><span class="hl-1">, [</span><br/><span class="hl-1">  </span><span class="hl-2">&#39;how can I return a product?&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-2">&#39;where is my order?&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-2">&#39;can you help me with a refund?&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-2">&#39;I need to update my shipping address&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-2">&#39;my product arrived damaged, what should I do?&#39;</span><br/><span class="hl-1">]);</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">technicalSupport</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">Route</span><span class="hl-1">(</span><span class="hl-2">&#39;technicalSupport&#39;</span><span class="hl-1">, [</span><br/><span class="hl-1">  </span><span class="hl-2">&#39;how do I install your software?&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-2">&#39;Iâ€™m having trouble logging in&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-2">&#39;can you help me configure my settings?&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-2">&#39;my application keeps crashing&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-2">&#39;how do I update to the latest version?&#39;</span><br/><span class="hl-1">]);</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">ai</span><span class="hl-1"> = </span><span class="hl-0">AI</span><span class="hl-1">(</span><span class="hl-2">&#39;openai&#39;</span><span class="hl-1">, { </span><span class="hl-5">apiKey:</span><span class="hl-1"> </span><span class="hl-5">process</span><span class="hl-1">.</span><span class="hl-5">env</span><span class="hl-1">.</span><span class="hl-7">OPENAI_APIKEY</span><span class="hl-1"> } </span><span class="hl-4">as</span><span class="hl-1"> </span><span class="hl-8">OpenAIArgs</span><span class="hl-1">);</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">router</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">Router</span><span class="hl-1">(</span><span class="hl-5">ai</span><span class="hl-1">);</span><br/><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-5">router</span><span class="hl-1">.</span><span class="hl-0">setRoutes</span><span class="hl-1">(</span><br/><span class="hl-1">  [</span><span class="hl-5">customerSupport</span><span class="hl-1">, </span><span class="hl-5">technicalSupport</span><span class="hl-1">],</span><br/><span class="hl-1">  { </span><span class="hl-5">filename:</span><span class="hl-1"> </span><span class="hl-2">&#39;router.json&#39;</span><span class="hl-1"> }</span><br/><span class="hl-1">);</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">tag</span><span class="hl-1"> = </span><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-5">router</span><span class="hl-1">.</span><span class="hl-0">forward</span><span class="hl-1">(</span><span class="hl-2">&#39;I need help with my order&#39;</span><span class="hl-1">);</span><br/><br/><span class="hl-4">if</span><span class="hl-1"> (</span><span class="hl-5">tag</span><span class="hl-1"> === </span><span class="hl-2">&quot;customerSupport&quot;</span><span class="hl-1">) {</span><br/><span class="hl-1">    ...</span><br/><span class="hl-1">}</span><br/><span class="hl-4">if</span><span class="hl-1"> (</span><span class="hl-5">tag</span><span class="hl-1"> === </span><span class="hl-2">&quot;technicalSupport&quot;</span><span class="hl-1">) {</span><br/><span class="hl-1">    ...</span><br/><span class="hl-1">}</span>
</code><button>Copy</button></pre>
<a id="md:vector-dbs-supported" class="tsd-anchor"></a><h2><a href="#md:vector-dbs-supported">Vector DBs Supported</a></h2><p>Vector databases are critical to building LLM workflows. We have clean abstractions over popular vector db&#39;s as well as our own quick in memory vector database.</p>
<table>
<thead>
<tr>
<th>Provider</th>
<th>Tested</th>
</tr>
</thead>
<tbody><tr>
<td>In Memory</td>
<td>ðŸŸ¢ 100%</td>
</tr>
<tr>
<td>Weaviate</td>
<td>ðŸŸ¢ 100%</td>
</tr>
<tr>
<td>Cloudflare</td>
<td>ðŸŸ¡ 50%</td>
</tr>
<tr>
<td>Pinecone</td>
<td>ðŸŸ¡ 50%</td>
</tr>
</tbody></table>
<pre><code class="language-typescript"><span class="hl-3">// Create embeddings from text using an LLM</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">ret</span><span class="hl-1"> = </span><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-6">this</span><span class="hl-1">.</span><span class="hl-5">ai</span><span class="hl-1">.</span><span class="hl-0">embed</span><span class="hl-1">({ </span><span class="hl-5">texts:</span><span class="hl-1"> </span><span class="hl-2">&#39;hello world&#39;</span><span class="hl-1"> });</span><br/><br/><span class="hl-3">// Create an in memory vector db</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">db</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">DB</span><span class="hl-1">(</span><span class="hl-2">&#39;memory&#39;</span><span class="hl-1">);</span><br/><br/><span class="hl-3">// Insert into vector db</span><br/><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-6">this</span><span class="hl-1">.</span><span class="hl-5">db</span><span class="hl-1">.</span><span class="hl-0">upsert</span><span class="hl-1">({</span><br/><span class="hl-1">  </span><span class="hl-5">id:</span><span class="hl-1"> </span><span class="hl-2">&#39;abc&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">table:</span><span class="hl-1"> </span><span class="hl-2">&#39;products&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">values:</span><span class="hl-1"> </span><span class="hl-5">ret</span><span class="hl-1">.</span><span class="hl-5">embeddings</span><span class="hl-1">[</span><span class="hl-9">0</span><span class="hl-1">]</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-3">// Query for similar entries using embeddings</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">matches</span><span class="hl-1"> = </span><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-6">this</span><span class="hl-1">.</span><span class="hl-5">db</span><span class="hl-1">.</span><span class="hl-0">query</span><span class="hl-1">({</span><br/><span class="hl-1">  </span><span class="hl-5">table:</span><span class="hl-1"> </span><span class="hl-2">&#39;products&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">values:</span><span class="hl-1"> </span><span class="hl-5">embeddings</span><span class="hl-1">[</span><span class="hl-9">0</span><span class="hl-1">]</span><br/><span class="hl-1">});</span>
</code><button>Copy</button></pre>
<p>Alternatively you can use the <code>DBManager</code> which handles smart chunking, embedding and querying everything
for you, it makes things almost too easy.</p>
<pre><code class="language-typescript"><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">manager</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">DBManager</span><span class="hl-1">({ </span><span class="hl-5">ai</span><span class="hl-1">, </span><span class="hl-5">db</span><span class="hl-1"> });</span><br/><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-5">manager</span><span class="hl-1">.</span><span class="hl-0">insert</span><span class="hl-1">(</span><span class="hl-5">text</span><span class="hl-1">);</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">matches</span><span class="hl-1"> = </span><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-5">manager</span><span class="hl-1">.</span><span class="hl-0">query</span><span class="hl-1">(</span><br/><span class="hl-1">  </span><span class="hl-2">&#39;John von Neumann on human intelligence and singularity.&#39;</span><br/><span class="hl-1">);</span><br/><span class="hl-5">console</span><span class="hl-1">.</span><span class="hl-0">log</span><span class="hl-1">(</span><span class="hl-5">matches</span><span class="hl-1">);</span>
</code><button>Copy</button></pre>
<a id="md:rag-documents" class="tsd-anchor"></a><h2><a href="#md:rag-documents">RAG Documents</a></h2><p>Using documents like PDF, DOCX, PPT, XLS, etc with LLMs is a huge pain. We make it easy with the help of Apache Tika an open source document processing engine.</p>
<p>Launch Apache Tika</p>
<pre><code class="language-shell"><span class="hl-0">docker</span><span class="hl-1"> </span><span class="hl-2">run</span><span class="hl-1"> </span><span class="hl-6">-p</span><span class="hl-1"> </span><span class="hl-9">9998</span><span class="hl-2">:9998</span><span class="hl-1"> </span><span class="hl-2">apache/tika</span>
</code><button>Copy</button></pre>
<p>Convert documents to text and embed them for retrieval using the <code>DBManager</code> it also supports a reranker and query rewriter. Two default implementations <code>DefaultResultReranker</code> and <code>DefaultQueryRewriter</code> are available to use.</p>
<pre><code class="language-typescript"><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">tika</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">ApacheTika</span><span class="hl-1">();</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">text</span><span class="hl-1"> = </span><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-5">tika</span><span class="hl-1">.</span><span class="hl-0">convert</span><span class="hl-1">(</span><span class="hl-2">&#39;/path/to/document.pdf&#39;</span><span class="hl-1">);</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">manager</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">DBManager</span><span class="hl-1">({ </span><span class="hl-5">ai</span><span class="hl-1">, </span><span class="hl-5">db</span><span class="hl-1"> });</span><br/><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-5">manager</span><span class="hl-1">.</span><span class="hl-0">insert</span><span class="hl-1">(</span><span class="hl-5">text</span><span class="hl-1">);</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">matches</span><span class="hl-1"> = </span><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-5">manager</span><span class="hl-1">.</span><span class="hl-0">query</span><span class="hl-1">(</span><span class="hl-2">&#39;Find some text&#39;</span><span class="hl-1">);</span><br/><span class="hl-5">console</span><span class="hl-1">.</span><span class="hl-0">log</span><span class="hl-1">(</span><span class="hl-5">matches</span><span class="hl-1">);</span>
</code><button>Copy</button></pre>
<a id="md:streaming" class="tsd-anchor"></a><h2><a href="#md:streaming">Streaming</a></h2><p>We support parsing output fields and function execution while streaming. This allows for fail-fast and error correction without having to wait for the whole output saving tokens, cost and reducing latency. Assertions are a powerful way to ensure the output matches your requirements these work with streaming as well.</p>
<pre><code class="language-typescript"><span class="hl-3">// setup the prompt program</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">gen</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">ChainOfThought</span><span class="hl-1">(</span><br/><span class="hl-1">  </span><span class="hl-5">ai</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-2">`startNumber:number -&gt; next10Numbers:number[]`</span><br/><span class="hl-1">);</span><br/><br/><span class="hl-3">// add a assertion to ensure that the number 5 is not in an output field</span><br/><span class="hl-5">gen</span><span class="hl-1">.</span><span class="hl-0">addAssert</span><span class="hl-1">(({ </span><span class="hl-5">next10Numbers</span><span class="hl-1"> }: </span><span class="hl-8">Readonly</span><span class="hl-1">&lt;{ </span><span class="hl-5">next10Numbers</span><span class="hl-1">: </span><span class="hl-8">number</span><span class="hl-1">[] }&gt;) </span><span class="hl-6">=&gt;</span><span class="hl-1"> {</span><br/><span class="hl-1">  </span><span class="hl-4">return</span><span class="hl-1"> </span><span class="hl-5">next10Numbers</span><span class="hl-1"> ? !</span><span class="hl-5">next10Numbers</span><span class="hl-1">.</span><span class="hl-0">includes</span><span class="hl-1">(</span><span class="hl-9">5</span><span class="hl-1">) : </span><span class="hl-6">undefined</span><span class="hl-1">;</span><br/><span class="hl-1">}, </span><span class="hl-2">&#39;Numbers 5 is not allowed&#39;</span><span class="hl-1">);</span><br/><br/><span class="hl-3">// run the program with streaming enabled</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">res</span><span class="hl-1"> = </span><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-5">gen</span><span class="hl-1">.</span><span class="hl-0">forward</span><span class="hl-1">({ </span><span class="hl-5">startNumber:</span><span class="hl-1"> </span><span class="hl-9">1</span><span class="hl-1"> }, { </span><span class="hl-5">stream:</span><span class="hl-1"> </span><span class="hl-6">true</span><span class="hl-1"> });</span>
</code><button>Copy</button></pre>
<p>The above example will allow you to validate entire output fields as they are streamed in. This validation works with streaming and when not streaming and is triggered when the entire field value is available. For true validation while streaming checkout the below example. This will massively improve performance and save tokens at scale in production</p>
<pre><code class="language-typescript"><span class="hl-3">// add a assertion to ensure all lines start with a number and a dot.</span><br/><span class="hl-5">gen</span><span class="hl-1">.</span><span class="hl-0">addStreamingAssert</span><span class="hl-1">(</span><br/><span class="hl-1">  </span><span class="hl-2">&#39;answerInPoints&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  (</span><span class="hl-5">value</span><span class="hl-1">: </span><span class="hl-8">string</span><span class="hl-1">) </span><span class="hl-6">=&gt;</span><span class="hl-1"> {</span><br/><span class="hl-1">    </span><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">re</span><span class="hl-1"> =</span><span class="hl-10"> /</span><span class="hl-11">^</span><span class="hl-10">\d</span><span class="hl-12">+</span><span class="hl-13">\.</span><span class="hl-10">/</span><span class="hl-1">;</span><br/><br/><span class="hl-1">    </span><span class="hl-3">// split the value by lines, trim each line,</span><br/><span class="hl-1">    </span><span class="hl-3">// filter out empty lines and check if all lines match the regex</span><br/><span class="hl-1">    </span><span class="hl-4">return</span><span class="hl-1"> </span><span class="hl-5">value</span><br/><span class="hl-1">      .</span><span class="hl-0">split</span><span class="hl-1">(</span><span class="hl-2">&#39;</span><span class="hl-13">\n</span><span class="hl-2">&#39;</span><span class="hl-1">)</span><br/><span class="hl-1">      .</span><span class="hl-0">map</span><span class="hl-1">((</span><span class="hl-5">x</span><span class="hl-1">) </span><span class="hl-6">=&gt;</span><span class="hl-1"> </span><span class="hl-5">x</span><span class="hl-1">.</span><span class="hl-0">trim</span><span class="hl-1">())</span><br/><span class="hl-1">      .</span><span class="hl-0">filter</span><span class="hl-1">((</span><span class="hl-5">x</span><span class="hl-1">) </span><span class="hl-6">=&gt;</span><span class="hl-1"> </span><span class="hl-5">x</span><span class="hl-1">.</span><span class="hl-5">length</span><span class="hl-1"> &gt; </span><span class="hl-9">0</span><span class="hl-1">)</span><br/><span class="hl-1">      .</span><span class="hl-0">every</span><span class="hl-1">((</span><span class="hl-5">x</span><span class="hl-1">) </span><span class="hl-6">=&gt;</span><span class="hl-1"> </span><span class="hl-5">re</span><span class="hl-1">.</span><span class="hl-0">test</span><span class="hl-1">(</span><span class="hl-5">x</span><span class="hl-1">));</span><br/><span class="hl-1">  },</span><br/><span class="hl-1">  </span><span class="hl-2">&#39;Lines must start with a number and a dot. Eg: 1. This is a line.&#39;</span><br/><span class="hl-1">);</span><br/><br/><span class="hl-3">// run the program with streaming enabled</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">res</span><span class="hl-1"> = </span><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-5">gen</span><span class="hl-1">.</span><span class="hl-0">forward</span><span class="hl-1">(</span><br/><span class="hl-1">  {</span><br/><span class="hl-1">    </span><span class="hl-5">question:</span><span class="hl-1"> </span><span class="hl-2">&#39;Provide a list of optimizations to speedup LLM inference.&#39;</span><br/><span class="hl-1">  },</span><br/><span class="hl-1">  { </span><span class="hl-5">stream:</span><span class="hl-1"> </span><span class="hl-6">true</span><span class="hl-1">, </span><span class="hl-5">debug:</span><span class="hl-1"> </span><span class="hl-6">true</span><span class="hl-1"> }</span><br/><span class="hl-1">);</span>
</code><button>Copy</button></pre>
<a id="md:opentelemetry-support" class="tsd-anchor"></a><h2><a href="#md:opentelemetry-support">OpenTelemetry support</a></h2><p>Ability to trace and observe your llm workflow is critical to building production workflows. OpenTelemetry is an industry standard and we support the new <code>gen_ai</code> attribute namespace.</p>
<pre><code class="language-typescript"><span class="hl-4">import</span><span class="hl-1"> { </span><span class="hl-5">trace</span><span class="hl-1"> } </span><span class="hl-4">from</span><span class="hl-1"> </span><span class="hl-2">&#39;@opentelemetry/api&#39;</span><span class="hl-1">;</span><br/><span class="hl-4">import</span><span class="hl-1"> {</span><br/><span class="hl-1">  </span><span class="hl-5">BasicTracerProvider</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">ConsoleSpanExporter</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">SimpleSpanProcessor</span><br/><span class="hl-1">} </span><span class="hl-4">from</span><span class="hl-1"> </span><span class="hl-2">&#39;@opentelemetry/sdk-trace-base&#39;</span><span class="hl-1">;</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">provider</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">BasicTracerProvider</span><span class="hl-1">();</span><br/><span class="hl-5">provider</span><span class="hl-1">.</span><span class="hl-0">addSpanProcessor</span><span class="hl-1">(</span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">SimpleSpanProcessor</span><span class="hl-1">(</span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">ConsoleSpanExporter</span><span class="hl-1">()));</span><br/><span class="hl-5">trace</span><span class="hl-1">.</span><span class="hl-0">setGlobalTracerProvider</span><span class="hl-1">(</span><span class="hl-5">provider</span><span class="hl-1">);</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">tracer</span><span class="hl-1"> = </span><span class="hl-5">trace</span><span class="hl-1">.</span><span class="hl-0">getTracer</span><span class="hl-1">(</span><span class="hl-2">&#39;test&#39;</span><span class="hl-1">);</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">ai</span><span class="hl-1"> = </span><span class="hl-0">AI</span><span class="hl-1">(</span><span class="hl-2">&#39;ollama&#39;</span><span class="hl-1">, {</span><br/><span class="hl-1">  </span><span class="hl-5">model:</span><span class="hl-1"> </span><span class="hl-2">&#39;nous-hermes2&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">options:</span><span class="hl-1"> { </span><span class="hl-5">tracer</span><span class="hl-1"> }</span><br/><span class="hl-1">} </span><span class="hl-4">as</span><span class="hl-1"> </span><span class="hl-8">unknown</span><span class="hl-1"> </span><span class="hl-4">as</span><span class="hl-1"> </span><span class="hl-8">OllamaArgs</span><span class="hl-1">);</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">gen</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">ChainOfThought</span><span class="hl-1">(</span><br/><span class="hl-1">  </span><span class="hl-5">ai</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-2">`text -&gt; shortSummary &quot;summarize in 5 to 10 words&quot;`</span><br/><span class="hl-1">);</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">res</span><span class="hl-1"> = </span><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-5">gen</span><span class="hl-1">.</span><span class="hl-0">forward</span><span class="hl-1">({ </span><span class="hl-5">text</span><span class="hl-1"> });</span>
</code><button>Copy</button></pre>
<pre><code class="language-json"><span class="hl-1">{</span><br/><span class="hl-1">  </span><span class="hl-14">&quot;traceId&quot;</span><span class="hl-1">: </span><span class="hl-2">&quot;ddc7405e9848c8c884e53b823e120845&quot;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-14">&quot;name&quot;</span><span class="hl-1">: </span><span class="hl-2">&quot;Chat Request&quot;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-14">&quot;id&quot;</span><span class="hl-1">: </span><span class="hl-2">&quot;d376daad21da7a3c&quot;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-14">&quot;kind&quot;</span><span class="hl-1">: </span><span class="hl-2">&quot;SERVER&quot;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-14">&quot;timestamp&quot;</span><span class="hl-1">: </span><span class="hl-9">1716622997025000</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-14">&quot;duration&quot;</span><span class="hl-1">: </span><span class="hl-9">14190456.542</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-14">&quot;attributes&quot;</span><span class="hl-1">: {</span><br/><span class="hl-1">    </span><span class="hl-14">&quot;gen_ai.system&quot;</span><span class="hl-1">: </span><span class="hl-2">&quot;Ollama&quot;</span><span class="hl-1">,</span><br/><span class="hl-1">    </span><span class="hl-14">&quot;gen_ai.request.model&quot;</span><span class="hl-1">: </span><span class="hl-2">&quot;nous-hermes2&quot;</span><span class="hl-1">,</span><br/><span class="hl-1">    </span><span class="hl-14">&quot;gen_ai.request.max_tokens&quot;</span><span class="hl-1">: </span><span class="hl-9">500</span><span class="hl-1">,</span><br/><span class="hl-1">    </span><span class="hl-14">&quot;gen_ai.request.temperature&quot;</span><span class="hl-1">: </span><span class="hl-9">0.1</span><span class="hl-1">,</span><br/><span class="hl-1">    </span><span class="hl-14">&quot;gen_ai.request.top_p&quot;</span><span class="hl-1">: </span><span class="hl-9">0.9</span><span class="hl-1">,</span><br/><span class="hl-1">    </span><span class="hl-14">&quot;gen_ai.request.frequency_penalty&quot;</span><span class="hl-1">: </span><span class="hl-9">0.5</span><span class="hl-1">,</span><br/><span class="hl-1">    </span><span class="hl-14">&quot;gen_ai.request.llm_is_streaming&quot;</span><span class="hl-1">: </span><span class="hl-6">false</span><span class="hl-1">,</span><br/><span class="hl-1">    </span><span class="hl-14">&quot;http.request.method&quot;</span><span class="hl-1">: </span><span class="hl-2">&quot;POST&quot;</span><span class="hl-1">,</span><br/><span class="hl-1">    </span><span class="hl-14">&quot;url.full&quot;</span><span class="hl-1">: </span><span class="hl-2">&quot;http://localhost:11434/v1/chat/completions&quot;</span><span class="hl-1">,</span><br/><span class="hl-1">    </span><span class="hl-14">&quot;gen_ai.usage.completion_tokens&quot;</span><span class="hl-1">: </span><span class="hl-9">160</span><span class="hl-1">,</span><br/><span class="hl-1">    </span><span class="hl-14">&quot;gen_ai.usage.prompt_tokens&quot;</span><span class="hl-1">: </span><span class="hl-9">290</span><br/><span class="hl-1">  }</span><br/><span class="hl-1">}</span>
</code><button>Copy</button></pre>
<p>Alternatively you can use the <code>DBManager</code> which handles smart chunking, embedding and querying everything
for you, it makes things almost too easy.</p>
<pre><code class="language-typescript"><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">manager</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">DBManager</span><span class="hl-1">({ </span><span class="hl-5">ai</span><span class="hl-1">, </span><span class="hl-5">db</span><span class="hl-1"> });</span><br/><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-5">manager</span><span class="hl-1">.</span><span class="hl-0">insert</span><span class="hl-1">(</span><span class="hl-5">text</span><span class="hl-1">);</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">matches</span><span class="hl-1"> = </span><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-5">manager</span><span class="hl-1">.</span><span class="hl-0">query</span><span class="hl-1">(</span><br/><span class="hl-1">  </span><span class="hl-2">&#39;John von Neumann on human intelligence and singularity.&#39;</span><br/><span class="hl-1">);</span><br/><span class="hl-5">console</span><span class="hl-1">.</span><span class="hl-0">log</span><span class="hl-1">(</span><span class="hl-5">matches</span><span class="hl-1">);</span>
</code><button>Copy</button></pre>
<a id="md:tuning-the-prompts-programs" class="tsd-anchor"></a><h2><a href="#md:tuning-the-prompts-programs">Tuning the prompts (programs)</a></h2><p>You can tune your prompts using a larger model to help them run more efficiently and give you better results. This is done by using an optimizer like <code>BootstrapFewShot</code> with and examples from the popular <code>HotPotQA</code> dataset. The optimizer generates demonstrations <code>demos</code> which when used with the prompt help improve its efficiency.</p>
<pre><code class="language-typescript"><span class="hl-3">// Download the HotPotQA dataset from huggingface</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">hf</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">HFDataLoader</span><span class="hl-1">();</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">examples</span><span class="hl-1"> = </span><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-5">hf</span><span class="hl-1">.</span><span class="hl-0">getData</span><span class="hl-1">&lt;{ </span><span class="hl-5">question</span><span class="hl-1">: </span><span class="hl-8">string</span><span class="hl-1">; </span><span class="hl-5">answer</span><span class="hl-1">: </span><span class="hl-8">string</span><span class="hl-1"> }&gt;({</span><br/><span class="hl-1">  </span><span class="hl-5">dataset:</span><span class="hl-1"> </span><span class="hl-2">&#39;hotpot_qa&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">split:</span><span class="hl-1"> </span><span class="hl-2">&#39;train&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">count:</span><span class="hl-1"> </span><span class="hl-9">100</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">fields:</span><span class="hl-1"> [</span><span class="hl-2">&#39;question&#39;</span><span class="hl-1">, </span><span class="hl-2">&#39;answer&#39;</span><span class="hl-1">]</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">ai</span><span class="hl-1"> = </span><span class="hl-0">AI</span><span class="hl-1">(</span><span class="hl-2">&#39;openai&#39;</span><span class="hl-1">, { </span><span class="hl-5">apiKey:</span><span class="hl-1"> </span><span class="hl-5">process</span><span class="hl-1">.</span><span class="hl-5">env</span><span class="hl-1">.</span><span class="hl-7">OPENAI_APIKEY</span><span class="hl-1"> } </span><span class="hl-4">as</span><span class="hl-1"> </span><span class="hl-8">OpenAIArgs</span><span class="hl-1">);</span><br/><br/><span class="hl-3">// Setup the program to tune</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">program</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">ChainOfThought</span><span class="hl-1">&lt;{ </span><span class="hl-5">question</span><span class="hl-1">: </span><span class="hl-8">string</span><span class="hl-1"> }, { </span><span class="hl-5">answer</span><span class="hl-1">: </span><span class="hl-8">string</span><span class="hl-1"> }&gt;(</span><br/><span class="hl-1">  </span><span class="hl-5">ai</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-2">`question -&gt; answer &quot;in short 2 or 3 words&quot;`</span><br/><span class="hl-1">);</span><br/><br/><span class="hl-3">// Setup a Bootstrap Few Shot optimizer to tune the above program</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">optimize</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">BootstrapFewShot</span><span class="hl-1">&lt;{ </span><span class="hl-5">question</span><span class="hl-1">: </span><span class="hl-8">string</span><span class="hl-1"> }, { </span><span class="hl-5">answer</span><span class="hl-1">: </span><span class="hl-8">string</span><span class="hl-1"> }&gt;(</span><br/><span class="hl-1">  {</span><br/><span class="hl-1">    </span><span class="hl-5">program</span><span class="hl-1">,</span><br/><span class="hl-1">    </span><span class="hl-5">examples</span><br/><span class="hl-1">  }</span><br/><span class="hl-1">);</span><br/><br/><span class="hl-3">// Setup a evaluation metric em, f1 scores are a popular way measure retrieval performance.</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-0">metricFn</span><span class="hl-1">: </span><span class="hl-8">MetricFn</span><span class="hl-1"> = ({ </span><span class="hl-5">prediction</span><span class="hl-1">, </span><span class="hl-5">example</span><span class="hl-1"> }) </span><span class="hl-6">=&gt;</span><br/><span class="hl-1">  </span><span class="hl-0">emScore</span><span class="hl-1">(</span><span class="hl-5">prediction</span><span class="hl-1">.</span><span class="hl-5">answer</span><span class="hl-1"> </span><span class="hl-4">as</span><span class="hl-1"> </span><span class="hl-8">string</span><span class="hl-1">, </span><span class="hl-5">example</span><span class="hl-1">.</span><span class="hl-5">answer</span><span class="hl-1"> </span><span class="hl-4">as</span><span class="hl-1"> </span><span class="hl-8">string</span><span class="hl-1">);</span><br/><br/><span class="hl-3">// Run the optimizer and save the result</span><br/><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-5">optimize</span><span class="hl-1">.</span><span class="hl-0">compile</span><span class="hl-1">(</span><span class="hl-5">metricFn</span><span class="hl-1">, { </span><span class="hl-5">filename:</span><span class="hl-1"> </span><span class="hl-2">&#39;demos.json&#39;</span><span class="hl-1"> });</span>
</code><button>Copy</button></pre>
<img width="853" alt="tune-prompt" src="https://github.com/dosco/llm-client/assets/832235/f924baa7-8922-424c-9c2c-f8b2018d8d74">

<p>And to use the generated demos with the above <code>ChainOfThought</code> program</p>
<pre><code class="language-typescript"><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">ai</span><span class="hl-1"> = </span><span class="hl-0">AI</span><span class="hl-1">(</span><span class="hl-2">&#39;openai&#39;</span><span class="hl-1">, { </span><span class="hl-5">apiKey:</span><span class="hl-1"> </span><span class="hl-5">process</span><span class="hl-1">.</span><span class="hl-5">env</span><span class="hl-1">.</span><span class="hl-7">OPENAI_APIKEY</span><span class="hl-1"> } </span><span class="hl-4">as</span><span class="hl-1"> </span><span class="hl-8">OpenAIArgs</span><span class="hl-1">);</span><br/><br/><span class="hl-3">// Setup the program to use the tuned data</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">program</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">ChainOfThought</span><span class="hl-1">&lt;{ </span><span class="hl-5">question</span><span class="hl-1">: </span><span class="hl-8">string</span><span class="hl-1"> }, { </span><span class="hl-5">answer</span><span class="hl-1">: </span><span class="hl-8">string</span><span class="hl-1"> }&gt;(</span><br/><span class="hl-1">  </span><span class="hl-5">ai</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-2">`question -&gt; answer &quot;in short 2 or 3 words&quot;`</span><br/><span class="hl-1">);</span><br/><br/><span class="hl-3">// load tuning data</span><br/><span class="hl-5">program</span><span class="hl-1">.</span><span class="hl-0">loadDemos</span><span class="hl-1">(</span><span class="hl-2">&#39;demos.json&#39;</span><span class="hl-1">);</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">res</span><span class="hl-1"> = </span><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-5">program</span><span class="hl-1">.</span><span class="hl-0">forward</span><span class="hl-1">({</span><br/><span class="hl-1">  </span><span class="hl-5">question:</span><span class="hl-1"> </span><span class="hl-2">&#39;What castle did David Gregory inherit?&#39;</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-5">console</span><span class="hl-1">.</span><span class="hl-0">log</span><span class="hl-1">(</span><span class="hl-5">res</span><span class="hl-1">);</span>
</code><button>Copy</button></pre>
<a id="md:checkout-all-the-examples" class="tsd-anchor"></a><h2><a href="#md:checkout-all-the-examples">Checkout all the examples</a></h2><p>Use the <code>tsx</code> command to run the examples it makes node run typescript code. It also support using a <code>.env</code> file to pass the AI API Keys as opposed to putting them in the commandline.</p>
<pre><code class="language-shell"><span class="hl-5">OPENAI_APIKEY</span><span class="hl-1">=</span><span class="hl-2">openai_key</span><span class="hl-1"> </span><span class="hl-0">npm</span><span class="hl-1"> </span><span class="hl-2">run</span><span class="hl-1"> </span><span class="hl-2">tsx</span><span class="hl-1"> </span><span class="hl-2">./src/examples/marketing.ts</span>
</code><button>Copy</button></pre>
<table>
<thead>
<tr>
<th>Example</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td>customer-support.ts</td>
<td>Extract valuable details from customer communications</td>
</tr>
<tr>
<td>food-search.ts</td>
<td>Use multiple APIs are used to find dinning options</td>
</tr>
<tr>
<td>marketing.ts</td>
<td>Generate short effective marketing sms messages</td>
</tr>
<tr>
<td>vectordb.ts</td>
<td>Chunk, embed and search text</td>
</tr>
<tr>
<td>fibonacci.ts</td>
<td>Use the JS code interpreter to compute fibonacci</td>
</tr>
<tr>
<td>summarize.ts</td>
<td>Generate a short summary of a large block of text</td>
</tr>
<tr>
<td>chain-of-thought.ts</td>
<td>Use chain-of-thought prompting to answer questions</td>
</tr>
<tr>
<td>rag.ts</td>
<td>Use multi-hop retrieval to answer questions</td>
</tr>
<tr>
<td>rag-docs.ts</td>
<td>Convert PDF to text and embed for rag search</td>
</tr>
<tr>
<td>react.ts</td>
<td>Use function calling and reasoning to answer questions</td>
</tr>
<tr>
<td>agent.ts</td>
<td>Agent framework, agents can use other agents, tools etc</td>
</tr>
<tr>
<td>qna-tune.ts</td>
<td>Use an optimizer to improve prompt efficiency</td>
</tr>
<tr>
<td>qna-use-tuned.ts</td>
<td>Use the optimized tuned prompts</td>
</tr>
<tr>
<td>streaming1.ts</td>
<td>Output fields validation while streaming</td>
</tr>
<tr>
<td>streaming2.ts</td>
<td>Per output field validation while streaming</td>
</tr>
</tbody></table>
<a id="md:built-in-functions" class="tsd-anchor"></a><h2><a href="#md:built-in-functions">Built-in Functions</a></h2><table>
<thead>
<tr>
<th>Function</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td>Code Interpreter</td>
<td>Used by the LLM to execute JS code in a sandboxed env.</td>
</tr>
<tr>
<td>Embeddings Adapter</td>
<td>Wrapper to fetch and pass embedding to your function</td>
</tr>
</tbody></table>
<a id="md:our-goal" class="tsd-anchor"></a><h2><a href="#md:our-goal">Our Goal</a></h2><p>Large language models (LLMs) are getting really powerful and have reached a point where they can work as the backend for your entire product. However there&#39;s still a lot of complexity to manage from using the right prompts, models, streaming, function calling, error-correction, and much more. Our goal is to package all this complexity into a well maintained easy to use library that can work with all the LLMs out there. Additionally we are using the latest research to add useful new capabilities like DSP to the library.</p>
<a id="md:how-to-use-this-library" class="tsd-anchor"></a><h2><a href="#md:how-to-use-this-library">How to use this library?</a></h2><a id="md:1-pick-an-ai-to-work-with" class="tsd-anchor"></a><h3><a href="#md:1-pick-an-ai-to-work-with">1. Pick an AI to work with</a></h3><pre><code class="language-ts"><span class="hl-3">// Pick a LLM</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">ai</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">OpenAI</span><span class="hl-1">({ </span><span class="hl-5">apiKey:</span><span class="hl-1"> </span><span class="hl-5">process</span><span class="hl-1">.</span><span class="hl-5">env</span><span class="hl-1">.</span><span class="hl-7">OPENAI_APIKEY</span><span class="hl-1"> } </span><span class="hl-4">as</span><span class="hl-1"> </span><span class="hl-8">OpenAIArgs</span><span class="hl-1">);</span>
</code><button>Copy</button></pre>
<a id="md:2-create-a-prompt-signature-based-on-your-usecase" class="tsd-anchor"></a><h3><a href="#md:2-create-a-prompt-signature-based-on-your-usecase">2. Create a prompt signature based on your usecase</a></h3><pre><code class="language-ts"><span class="hl-3">// Signature defines the inputs and outputs of your prompt program</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">cot</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">ChainOfThought</span><span class="hl-1">(</span><span class="hl-5">ai</span><span class="hl-1">, </span><span class="hl-2">`question:string -&gt; answer:string`</span><span class="hl-1">, { </span><span class="hl-5">mem</span><span class="hl-1"> });</span>
</code><button>Copy</button></pre>
<a id="md:3-execute-this-new-prompt-program" class="tsd-anchor"></a><h3><a href="#md:3-execute-this-new-prompt-program">3. Execute this new prompt program</a></h3><pre><code class="language-ts"><span class="hl-3">// Pass in the input fields defined in the above signature</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">res</span><span class="hl-1"> = </span><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-5">cot</span><span class="hl-1">.</span><span class="hl-0">forward</span><span class="hl-1">({ </span><span class="hl-5">question:</span><span class="hl-1"> </span><span class="hl-2">&#39;Are we in a simulation?&#39;</span><span class="hl-1"> });</span>
</code><button>Copy</button></pre>
<a id="md:4-or-if-you-just-want-to-directly-use-the-llm" class="tsd-anchor"></a><h3><a href="#md:4-or-if-you-just-want-to-directly-use-the-llm">4. Or if you just want to directly use the LLM</a></h3><pre><code class="language-ts"><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">res</span><span class="hl-1"> = </span><span class="hl-4">await</span><span class="hl-1"> </span><span class="hl-5">ai</span><span class="hl-1">.</span><span class="hl-0">chat</span><span class="hl-1">([</span><br/><span class="hl-1">  { </span><span class="hl-5">role:</span><span class="hl-1"> </span><span class="hl-2">&quot;system&quot;</span><span class="hl-1">, </span><span class="hl-5">content:</span><span class="hl-1"> </span><span class="hl-2">&quot;Help the customer with his questions&quot;</span><span class="hl-1"> }</span><br/><span class="hl-1">  { </span><span class="hl-5">role:</span><span class="hl-1"> </span><span class="hl-2">&quot;user&quot;</span><span class="hl-1">, </span><span class="hl-5">content:</span><span class="hl-1"> </span><span class="hl-2">&quot;I&#39;m looking for a Macbook Pro M2 With 96GB RAM?&quot;</span><span class="hl-1"> }</span><br/><span class="hl-1">]);</span>
</code><button>Copy</button></pre>
<a id="md:how-do-you-use-function-calling" class="tsd-anchor"></a><h2><a href="#md:how-do-you-use-function-calling">How do you use function calling</a></h2><a id="md:1-define-the-functions" class="tsd-anchor"></a><h3><a href="#md:1-define-the-functions">1. Define the functions</a></h3><pre><code class="language-ts"><span class="hl-3">// define one or more functions and a function handler</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">functions</span><span class="hl-1"> = [</span><br/><span class="hl-1">  {</span><br/><span class="hl-1">    </span><span class="hl-5">name:</span><span class="hl-1"> </span><span class="hl-2">&#39;getCurrentWeather&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">    </span><span class="hl-5">description:</span><span class="hl-1"> </span><span class="hl-2">&#39;get the current weather for a location&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">    </span><span class="hl-5">parameters:</span><span class="hl-1"> {</span><br/><span class="hl-1">      </span><span class="hl-5">type:</span><span class="hl-1"> </span><span class="hl-2">&#39;object&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">      </span><span class="hl-5">properties:</span><span class="hl-1"> {</span><br/><span class="hl-1">        </span><span class="hl-5">location:</span><span class="hl-1"> {</span><br/><span class="hl-1">          </span><span class="hl-5">type:</span><span class="hl-1"> </span><span class="hl-2">&#39;string&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">          </span><span class="hl-5">description:</span><span class="hl-1"> </span><span class="hl-2">&#39;location to get weather for&#39;</span><br/><span class="hl-1">        },</span><br/><span class="hl-1">        </span><span class="hl-5">units:</span><span class="hl-1"> {</span><br/><span class="hl-1">          </span><span class="hl-5">type:</span><span class="hl-1"> </span><span class="hl-2">&#39;string&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">          </span><span class="hl-5">enum:</span><span class="hl-1"> [</span><span class="hl-2">&#39;imperial&#39;</span><span class="hl-1">, </span><span class="hl-2">&#39;metric&#39;</span><span class="hl-1">],</span><br/><span class="hl-1">          </span><span class="hl-5">default:</span><span class="hl-1"> </span><span class="hl-2">&#39;imperial&#39;</span><span class="hl-1">,</span><br/><span class="hl-1">          </span><span class="hl-5">description:</span><span class="hl-1"> </span><span class="hl-2">&#39;units to use&#39;</span><br/><span class="hl-1">        }</span><br/><span class="hl-1">      },</span><br/><span class="hl-1">      </span><span class="hl-5">required:</span><span class="hl-1"> [</span><span class="hl-2">&#39;location&#39;</span><span class="hl-1">]</span><br/><span class="hl-1">    },</span><br/><span class="hl-1">    </span><span class="hl-0">func</span><span class="hl-5">:</span><span class="hl-1"> </span><span class="hl-6">async</span><span class="hl-1"> (</span><span class="hl-5">args</span><span class="hl-1">: </span><span class="hl-8">Readonly</span><span class="hl-1">&lt;{ </span><span class="hl-5">location</span><span class="hl-1">: </span><span class="hl-8">string</span><span class="hl-1">; </span><span class="hl-5">units</span><span class="hl-1">: </span><span class="hl-8">string</span><span class="hl-1"> }&gt;) </span><span class="hl-6">=&gt;</span><span class="hl-1"> {</span><br/><span class="hl-1">      </span><span class="hl-4">return</span><span class="hl-1"> </span><span class="hl-2">`The weather in </span><span class="hl-6">${</span><span class="hl-5">args</span><span class="hl-15">.</span><span class="hl-5">location</span><span class="hl-6">}</span><span class="hl-2"> is 72 degrees`</span><span class="hl-1">;</span><br/><span class="hl-1">    }</span><br/><span class="hl-1">  }</span><br/><span class="hl-1">];</span>
</code><button>Copy</button></pre>
<a id="md:2-pass-the-functions-to-a-prompt" class="tsd-anchor"></a><h3><a href="#md:2-pass-the-functions-to-a-prompt">2. Pass the functions to a prompt</a></h3><pre><code class="language-ts"><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">cot</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">ReAct</span><span class="hl-1">(</span><span class="hl-5">ai</span><span class="hl-1">, </span><span class="hl-2">`question:string -&gt; answer:string`</span><span class="hl-1">, { </span><span class="hl-5">functions</span><span class="hl-1"> });</span>
</code><button>Copy</button></pre>
<a id="md:enable-debug-logs" class="tsd-anchor"></a><h2><a href="#md:enable-debug-logs">Enable debug logs</a></h2><pre><code class="language-ts"><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">ai</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">OpenAI</span><span class="hl-1">({ </span><span class="hl-5">apiKey:</span><span class="hl-1"> </span><span class="hl-5">process</span><span class="hl-1">.</span><span class="hl-5">env</span><span class="hl-1">.</span><span class="hl-7">OPENAI_APIKEY</span><span class="hl-1"> } </span><span class="hl-4">as</span><span class="hl-1"> </span><span class="hl-8">OpenAIArgs</span><span class="hl-1">);</span><br/><span class="hl-5">ai</span><span class="hl-1">.</span><span class="hl-0">setOptions</span><span class="hl-1">({ </span><span class="hl-5">debug:</span><span class="hl-1"> </span><span class="hl-6">true</span><span class="hl-1"> });</span>
</code><button>Copy</button></pre>
<a id="md:reach-out" class="tsd-anchor"></a><h2><a href="#md:reach-out">Reach out</a></h2><p>We&#39;re happy to help reach out if you have questions or join the Discord
<a href="https://twitter.com/dosco">twitter/dosco</a></p>
<a id="md:faq" class="tsd-anchor"></a><h2><a href="#md:faq">FAQ</a></h2><a id="md:1-the-llm-can39t-find-the-right-function-to-use" class="tsd-anchor"></a><h3><a href="#md:1-the-llm-can39t-find-the-right-function-to-use">1. The LLM can&#39;t find the right function to use</a></h3><p>Improve the function naming and description be very clear on what the function does. Also ensure the function parameter&#39;s also have good descriptions. The descriptions don&#39;t have to be very long but need to be clear.</p>
<a id="md:2-how-do-i-change-the-configuration-of-the-llm-used" class="tsd-anchor"></a><h3><a href="#md:2-how-do-i-change-the-configuration-of-the-llm-used">2. How do I change the configuration of the LLM used</a></h3><p>You can pass a configuration object as the second parameter when creating a new LLM object</p>
<pre><code class="language-ts"><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">apiKey</span><span class="hl-1"> = </span><span class="hl-5">process</span><span class="hl-1">.</span><span class="hl-5">env</span><span class="hl-1">.</span><span class="hl-7">OPENAI_APIKEY</span><span class="hl-1">;</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">conf</span><span class="hl-1"> = </span><span class="hl-0">OpenAIBestConfig</span><span class="hl-1">();</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">ai</span><span class="hl-1"> = </span><span class="hl-6">new</span><span class="hl-1"> </span><span class="hl-0">OpenAI</span><span class="hl-1">({ </span><span class="hl-5">apiKey</span><span class="hl-1">, </span><span class="hl-5">conf</span><span class="hl-1"> } </span><span class="hl-4">as</span><span class="hl-1"> </span><span class="hl-8">OpenAIArgs</span><span class="hl-1">);</span>
</code><button>Copy</button></pre>
<a id="md:3-my-prompt-is-too-long-and-can-i-change-the-max-tokens" class="tsd-anchor"></a><h2><a href="#md:3-my-prompt-is-too-long-and-can-i-change-the-max-tokens">3. My prompt is too long and can I change the max tokens</a></h2><pre><code class="language-ts"><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">conf</span><span class="hl-1"> = </span><span class="hl-0">OpenAIDefaultConfig</span><span class="hl-1">(); </span><span class="hl-3">// or OpenAIBestOptions()</span><br/><span class="hl-5">conf</span><span class="hl-1">.</span><span class="hl-5">maxTokens</span><span class="hl-1"> = </span><span class="hl-9">2000</span><span class="hl-1">;</span>
</code><button>Copy</button></pre>
<a id="md:4-how-do-i-change-the-model-say-i-want-to-use-gpt4" class="tsd-anchor"></a><h2><a href="#md:4-how-do-i-change-the-model-say-i-want-to-use-gpt4">4. How do I change the model say I want to use GPT4</a></h2><pre><code class="language-ts"><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">conf</span><span class="hl-1"> = </span><span class="hl-0">OpenAIDefaultConfig</span><span class="hl-1">(); </span><span class="hl-3">// or OpenAIBestOptions()</span><br/><span class="hl-5">conf</span><span class="hl-1">.</span><span class="hl-5">model</span><span class="hl-1"> = </span><span class="hl-5">OpenAIModel</span><span class="hl-1">.</span><span class="hl-5">GPT4Turbo</span><span class="hl-1">;</span>
</code><button>Copy</button></pre>
</div></div><div class="col-sidebar"><div class="page-menu"><div class="tsd-navigation settings"><details class="tsd-index-accordion"><summary class="tsd-accordion-summary"><h3><svg width="20" height="20" viewBox="0 0 24 24" fill="none"><use href="assets/icons.svg#icon-chevronDown"></use></svg>Settings</h3></summary><div class="tsd-accordion-details"><div class="tsd-filter-visibility"><h4 class="uppercase">Member Visibility</h4><form><ul id="tsd-filter-options"><li class="tsd-filter-item"><label class="tsd-filter-input"><input type="checkbox" id="tsd-filter-protected" name="protected"/><svg width="32" height="32" viewBox="0 0 32 32" aria-hidden="true"><rect class="tsd-checkbox-background" width="30" height="30" x="1" y="1" rx="6" fill="none"></rect><path class="tsd-checkbox-checkmark" d="M8.35422 16.8214L13.2143 21.75L24.6458 10.25" stroke="none" stroke-width="3.5" stroke-linejoin="round" fill="none"></path></svg><span>Protected</span></label></li><li class="tsd-filter-item"><label class="tsd-filter-input"><input type="checkbox" id="tsd-filter-private" name="private"/><svg width="32" height="32" viewBox="0 0 32 32" aria-hidden="true"><rect class="tsd-checkbox-background" width="30" height="30" x="1" y="1" rx="6" fill="none"></rect><path class="tsd-checkbox-checkmark" d="M8.35422 16.8214L13.2143 21.75L24.6458 10.25" stroke="none" stroke-width="3.5" stroke-linejoin="round" fill="none"></path></svg><span>Private</span></label></li><li class="tsd-filter-item"><label class="tsd-filter-input"><input type="checkbox" id="tsd-filter-inherited" name="inherited" checked/><svg width="32" height="32" viewBox="0 0 32 32" aria-hidden="true"><rect class="tsd-checkbox-background" width="30" height="30" x="1" y="1" rx="6" fill="none"></rect><path class="tsd-checkbox-checkmark" d="M8.35422 16.8214L13.2143 21.75L24.6458 10.25" stroke="none" stroke-width="3.5" stroke-linejoin="round" fill="none"></path></svg><span>Inherited</span></label></li><li class="tsd-filter-item"><label class="tsd-filter-input"><input type="checkbox" id="tsd-filter-external" name="external"/><svg width="32" height="32" viewBox="0 0 32 32" aria-hidden="true"><rect class="tsd-checkbox-background" width="30" height="30" x="1" y="1" rx="6" fill="none"></rect><path class="tsd-checkbox-checkmark" d="M8.35422 16.8214L13.2143 21.75L24.6458 10.25" stroke="none" stroke-width="3.5" stroke-linejoin="round" fill="none"></path></svg><span>External</span></label></li></ul></form></div><div class="tsd-theme-toggle"><h4 class="uppercase">Theme</h4><select id="tsd-theme"><option value="os">OS</option><option value="light">Light</option><option value="dark">Dark</option></select></div></div></details></div><details open class="tsd-index-accordion tsd-page-navigation"><summary class="tsd-accordion-summary"><h3><svg width="20" height="20" viewBox="0 0 24 24" fill="none"><use href="assets/icons.svg#icon-chevronDown"></use></svg>On This Page</h3></summary><div class="tsd-accordion-details"><a href="#md:ax---build-llms-powered-agents-typescript"><span>Ax -<wbr/> <wbr/>Build LLMs <wbr/>Powered <wbr/>Agents (<wbr/>Typescript)</span></a><ul><li><a href="#md:build-with-prompt-signatures"><span>Build with prompt signatures</span></a></li><li><a href="#md:why-use-ax"><span>Why use <wbr/>Ax?</span></a></li><li><a href="#md:whats-a-prompt-signature"><span>Whats a prompt signature?</span></a></li><li><a href="#md:llms-supported"><span>LLMs <wbr/>Supported</span></a></li><li><a href="#md:install"><span>Install</span></a></li><li><a href="#md:example-using-chain-of-thought-to-summarize-text"><span>Example: <wbr/>Using chain-<wbr/>of-<wbr/>thought to summarize text</span></a></li><li><a href="#md:example-building-an-agent"><span>Example: <wbr/>Building an agent</span></a></li><li><a href="#md:fast-llm-router"><span>Fast LLM <wbr/>Router</span></a></li><li><a href="#md:vector-dbs-supported"><span>Vector DBs <wbr/>Supported</span></a></li><li><a href="#md:rag-documents"><span>RAG <wbr/>Documents</span></a></li><li><a href="#md:streaming"><span>Streaming</span></a></li><li><a href="#md:opentelemetry-support"><span>Open<wbr/>Telemetry support</span></a></li><li><a href="#md:tuning-the-prompts-programs"><span>Tuning the prompts (programs)</span></a></li><li><a href="#md:checkout-all-the-examples"><span>Checkout all the examples</span></a></li><li><a href="#md:built-in-functions"><span>Built-<wbr/>in <wbr/>Functions</span></a></li><li><a href="#md:our-goal"><span>Our <wbr/>Goal</span></a></li><li><a href="#md:how-to-use-this-library"><span>How to use this library?</span></a></li><li><ul><li><a href="#md:1-pick-an-ai-to-work-with"><span>1. <wbr/>Pick an AI to work with</span></a></li><li><a href="#md:2-create-a-prompt-signature-based-on-your-usecase"><span>2. <wbr/>Create a prompt signature based on your usecase</span></a></li><li><a href="#md:3-execute-this-new-prompt-program"><span>3. <wbr/>Execute this new prompt program</span></a></li><li><a href="#md:4-or-if-you-just-want-to-directly-use-the-llm"><span>4. <wbr/>Or if you just want to directly use the LLM</span></a></li></ul></li><li><a href="#md:how-do-you-use-function-calling"><span>How do you use function calling</span></a></li><li><ul><li><a href="#md:1-define-the-functions"><span>1. <wbr/>Define the functions</span></a></li><li><a href="#md:2-pass-the-functions-to-a-prompt"><span>2. <wbr/>Pass the functions to a prompt</span></a></li></ul></li><li><a href="#md:enable-debug-logs"><span>Enable debug logs</span></a></li><li><a href="#md:reach-out"><span>Reach out</span></a></li><li><a href="#md:faq"><span>FAQ</span></a></li><li><ul><li><a href="#md:1-the-llm-can39t-find-the-right-function-to-use"><span>1. <wbr/>The LLM can&#39;t find the right function to use</span></a></li><li><a href="#md:2-how-do-i-change-the-configuration-of-the-llm-used"><span>2. <wbr/>How do <wbr/>I change the configuration of the LLM used</span></a></li></ul></li><li><a href="#md:3-my-prompt-is-too-long-and-can-i-change-the-max-tokens"><span>3. <wbr/>My prompt is too long and can <wbr/>I change the max tokens</span></a></li><li><a href="#md:4-how-do-i-change-the-model-say-i-want-to-use-gpt4"><span>4. <wbr/>How do <wbr/>I change the model say <wbr/>I want to use GPT4</span></a></li></ul></div></details></div><div class="site-menu"><nav class="tsd-navigation"><a href="modules.html" class="current"><svg class="tsd-kind-icon" viewBox="0 0 24 24"><use href="assets/icons.svg#icon-1"></use></svg><span>@ax-llm/ax</span></a><ul class="tsd-small-nested-navigation" id="tsd-nav-container" data-base="."><li>Loading...</li></ul></nav></div></div></div><footer><p class="tsd-generator">Generated using <a href="https://typedoc.org/" target="_blank">TypeDoc</a></p></footer><div class="overlay"></div></body></html>